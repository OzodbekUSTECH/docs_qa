import logging
from dataclasses import dataclass
from typing import Sequence

from sqlalchemy import Select, func, literal, select, text, union_all
from sqlalchemy.ext.asyncio import AsyncSession

from app.entities import Document, DocumentChunk
from app.repositories.base import BaseRepository

logger = logging.getLogger("app.repositories.documents")


# ---- cross-version helper for cosine distance ----
# —Ä–∞–±–æ—Ç–∞–µ—Ç —Å: col.cosine_distance(vec) –ò–õ–ò –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–º <=> –ò–õ–ò func.cosine_distance
def cos_dist(col, vec):
    try:
        return col.cosine_distance(vec)  # —É –Ω–æ–≤—ã—Ö pgvector –∫–æ–ª–æ–Ω–∫–∞ –∏–º–µ–µ—Ç –º–µ—Ç–æ–¥
    except Exception:
        pass
    try:
        return col.op("<=>")(vec)        # –æ–ø–µ—Ä–∞—Ç–æ—Ä pgvector (—Å–∞–º—ã–π —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π)
    except Exception:
        pass
    return func.cosine_distance(col, vec)  # –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç


@dataclass
class SearchHit:
    chunk: DocumentChunk
    text_rank: float
    vec_score: float
    hybrid_score: float


class DocumentsRepository(BaseRepository[Document]):
    def __init__(self, session: AsyncSession):
        super().__init__(session, entity=Document)


class DocumentChunksRepository(BaseRepository[DocumentChunk]):
    def __init__(self, session: AsyncSession):
        super().__init__(session, entity=DocumentChunk)

    # ---------- filters ----------
    def _apply_filters(
        self,
        stmt: Select,
        *,
        document_ids: Sequence[int] | None,
        exclude_document_ids: Sequence[int] | None,
        include_chunk_ids: Sequence[int] | None,
        exclude_chunk_ids: Sequence[int] | None,
    ) -> Select:
        if document_ids:
            stmt = stmt.where(DocumentChunk.document_id.in_(document_ids))
        if exclude_document_ids:
            stmt = stmt.where(~DocumentChunk.document_id.in_(exclude_document_ids))
        if include_chunk_ids:
            stmt = stmt.where(DocumentChunk.id.in_(include_chunk_ids))
        if exclude_chunk_ids:
            stmt = stmt.where(~DocumentChunk.id.in_(exclude_chunk_ids))
        return stmt

    # ---------- pure FTS ----------
    async def fts_search(
        self,
        *,
        query_text: str,
        limit: int = 20,
        document_ids: Sequence[int] | None = None,
        exclude_document_ids: Sequence[int] | None = None,
        include_chunk_ids: Sequence[int] | None = None,
        exclude_chunk_ids: Sequence[int] | None = None,
    ) -> list[SearchHit]:
        if not (query_text and query_text.strip()):
            logger.warning("fts_search: empty query_text, returning empty list")
            return []

        logger.info("fts_search: searching with query_text='%s', limit=%d", query_text, limit)
        
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ PostgreSQL tsvector
            # –°—Ç—Ä–æ–∏–º tsquery —á–µ—Ä–µ–∑ SQL —Ñ—É–Ω–∫—Ü–∏–∏ PostgreSQL –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º replace –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –ø—Ä–æ–±–µ–ª–æ–≤ –≤ OR –æ–ø–µ—Ä–∞—Ç–æ—Ä—ã
            ts_query = func.to_tsquery(
                "simple",
                func.replace(func.unaccent(query_text), " ", " | ")
            )
            text_rank = func.ts_rank_cd(DocumentChunk.content_tsv, ts_query)

            stmt: Select = (
                select(
                    DocumentChunk,
                    text_rank.label("text_rank"),
                    literal(0.0).label("vec_score"),
                    text_rank.label("hybrid_score"),
                )
                .where(DocumentChunk.content_tsv.op("@@")(ts_query))
            )
            stmt = self._apply_filters(
                stmt,
                document_ids=document_ids,
                exclude_document_ids=exclude_document_ids,
                include_chunk_ids=include_chunk_ids,
                exclude_chunk_ids=exclude_chunk_ids,
            ).order_by(text_rank.desc()).limit(limit)

            res = await self.session.execute(stmt)
            rows = res.all()
            hits = [
                SearchHit(
                    chunk=r[0],
                    text_rank=float(r[1] or 0),
                    vec_score=float(r[2] or 0),
                    hybrid_score=float(r[3] or 0),
                )
                for r in rows
            ]
            logger.info("fts_search: found %d hits", len(hits))
            return hits
        except Exception as e:
            logger.error("fts_search: error executing search: %s", str(e), exc_info=True)
            return []

    # ---------- pure vector ----------
    async def vector_search(
        self,
        *,
        query_embedding: Sequence[float],
        limit: int = 20,
        document_ids: Sequence[int] | None = None,
        exclude_document_ids: Sequence[int] | None = None,
        include_chunk_ids: Sequence[int] | None = None,
        exclude_chunk_ids: Sequence[int] | None = None,
    ) -> list[SearchHit]:
        if not query_embedding:
            logger.warning("vector_search: empty query_embedding, returning empty list")
            return []

        logger.info("vector_search: searching with embedding length=%d, limit=%d", len(query_embedding), limit)
        
        try:
            dist = cos_dist(DocumentChunk.embedding, query_embedding)
            vec_score = literal(1.0) - dist

            stmt: Select = select(
                DocumentChunk,
                literal(0.0).label("text_rank"),
                vec_score.label("vec_score"),
                vec_score.label("hybrid_score"),
            )
            stmt = self._apply_filters(
                stmt,
                document_ids=document_ids,
                exclude_document_ids=exclude_document_ids,
                include_chunk_ids=include_chunk_ids,
                exclude_chunk_ids=exclude_chunk_ids,
            ).order_by(vec_score.desc()).limit(limit)

            res = await self.session.execute(stmt)
            rows = res.all()
            hits = [
                SearchHit(
                    chunk=r[0],
                    text_rank=float(r[1] or 0),
                    vec_score=float(r[2] or 0),
                    hybrid_score=float(r[3] or 0),
                )
                for r in rows
            ]
            logger.info("vector_search: found %d hits", len(hits))
            return hits
        except Exception as e:
            logger.error("vector_search: error executing search: %s", str(e), exc_info=True)
            return []

    # ---------- independent union + re-rank ----------
    async def independent_hybrid_search(
        self,
        *,
        query_text: str,
        query_embedding: Sequence[float],
        document_ids: Sequence[int] | None = None,
        exclude_document_ids: Sequence[int] | None = None,
        include_chunk_ids: Sequence[int] | None = None,
        exclude_chunk_ids: Sequence[int] | None = None,
        limit: int = 8,
        k_text: int = 64,
        k_vector: int = 64,
        text_weight: float = 0.6,
        vector_weight: float = 0.4,
    ) -> list[SearchHit]:
        logger.info(
            "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n"
            "‚ïë INDEPENDENT HYBRID SEARCH                                    ‚ïë\n"
            "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n"
            "‚ïë Query: %-55s ‚ïë\n"
            "‚ïë Embedding length: %-45d ‚ïë\n"
            "‚ïë Limit: %-54d ‚ïë\n"
            "‚ïë K values: text=%d, vector=%d                                ‚ïë\n"
            "‚ïë Weights: text=%.2f, vector=%.2f                              ‚ïë\n"
            "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù",
            (query_text[:55] if query_text else "None"),
            len(query_embedding) if query_embedding else 0,
            limit,
            k_text,
            k_vector,
            text_weight,
            vector_weight,
        )

        has_text = query_text and query_text.strip()
        has_vector = query_embedding and len(query_embedding) > 0

        if not has_text and not has_vector:
            logger.warning("independent_hybrid_search: no query_text or query_embedding, returning empty list")
            return []

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ –±–∞–∑–µ
        total_chunks_stmt = select(func.count(DocumentChunk.id))
        if document_ids:
            total_chunks_stmt = total_chunks_stmt.where(DocumentChunk.document_id.in_(document_ids))
        total_chunks_result = await self.session.execute(total_chunks_stmt)
        total_chunks_count = total_chunks_result.scalar() or 0
        logger.info("üìä Total chunks in database: %d", total_chunks_count)
        
        if total_chunks_count == 0:
            logger.warning("independent_hybrid_search: no chunks found in database")
            return []

        # –ï—Å–ª–∏ –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç –∏–ª–∏ —Ç–æ–ª—å–∫–æ –≤–µ–∫—Ç–æ—Ä, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫
        if has_text and not has_vector:
            logger.info("independent_hybrid_search: text-only search, using fts_search")
            return await self.fts_search(
                query_text=query_text,
                limit=limit,
                document_ids=document_ids,
                exclude_document_ids=exclude_document_ids,
                include_chunk_ids=include_chunk_ids,
                exclude_chunk_ids=exclude_chunk_ids,
            )
        
        if has_vector and not has_text:
            logger.info("independent_hybrid_search: vector-only search, using vector_search")
            return await self.vector_search(
                query_embedding=query_embedding,
                limit=limit,
                document_ids=document_ids,
                exclude_document_ids=exclude_document_ids,
                include_chunk_ids=include_chunk_ids,
                exclude_chunk_ids=exclude_chunk_ids,
            )

        # –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫: –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã FTS –∏ Vector
            logger.info("üîÑ Performing hybrid search...")
        
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ PostgreSQL tsvector
            # –°—Ç—Ä–æ–∏–º tsquery —á–µ—Ä–µ–∑ SQL —Ñ—É–Ω–∫—Ü–∏–∏ PostgreSQL –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º replace –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –ø—Ä–æ–±–µ–ª–æ–≤ –≤ OR –æ–ø–µ—Ä–∞—Ç–æ—Ä—ã
            ts_query = func.to_tsquery(
                "simple",
                func.replace(func.unaccent(query_text), " ", " | ")
            )
            text_rank = func.ts_rank_cd(DocumentChunk.content_tsv, ts_query)
            dist = cos_dist(DocumentChunk.embedding, query_embedding)
            vec_score = literal(1.0) - dist

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ ts_query (–¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
            try:
                ts_query_test_stmt = select(ts_query.label("ts_query_value"))
                ts_query_test_result = await self.session.execute(ts_query_test_stmt)
                ts_query_value = ts_query_test_result.scalar()
                logger.info("independent_hybrid_search: ts_query result='%s'", ts_query_value)
                if not ts_query_value or str(ts_query_value).strip() == '':
                    logger.warning(
                        "independent_hybrid_search: ts_query is empty for query '%s'. "
                        "FTS search will not work properly.",
                        query_text
                    )
            except Exception as e:
                logger.debug("independent_hybrid_search: could not test ts_query: %s", str(e))

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∫–æ–ª—å–∫–æ chunks —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç FTS —É—Å–ª–æ–≤–∏—é
            fts_count_stmt = select(func.count(DocumentChunk.id)).where(
                DocumentChunk.content_tsv.op("@@")(ts_query)
            )
            fts_count_stmt = self._apply_filters(
                fts_count_stmt,
                document_ids=document_ids,
                exclude_document_ids=exclude_document_ids,
                include_chunk_ids=include_chunk_ids,
                exclude_chunk_ids=exclude_chunk_ids,
            )
            fts_count_result = await self.session.execute(fts_count_stmt)
            fts_count = fts_count_result.scalar() or 0
            logger.info("independent_hybrid_search: FTS matches found=%d (query='%s')", fts_count, query_text)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∫–æ–ª—å–∫–æ chunks –∏–º–µ—é—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–π content_tsv
            tsv_check_stmt = select(func.count(DocumentChunk.id)).where(
                DocumentChunk.content_tsv.isnot(None)
            )
            if document_ids:
                tsv_check_stmt = tsv_check_stmt.where(DocumentChunk.document_id.in_(document_ids))
            tsv_check_result = await self.session.execute(tsv_check_stmt)
            tsv_count = tsv_check_result.scalar() or 0
            logger.info("independent_hybrid_search: chunks with content_tsv=%d/%d", tsv_count, total_chunks_count)
            
            # –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê: –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ä–µ–∞–ª—å–Ω–æ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ content –∏ content_tsv
            try:
                if document_ids:
                    debug_stmt = text("""
                        SELECT 
                            id,
                            LEFT(content, 200) as content_preview,
                            content_tsv::text as tsv_text,
                            to_tsvector('simple', unaccent(content))::text as computed_tsv
                        FROM document_chunks
                        WHERE document_id = ANY(:doc_ids)
                        LIMIT 3
                    """)
                    debug_result = await self.session.execute(debug_stmt, {"doc_ids": list(document_ids)})
                else:
                    debug_stmt = text("""
                        SELECT 
                            id,
                            LEFT(content, 200) as content_preview,
                            content_tsv::text as tsv_text,
                            to_tsvector('simple', unaccent(content))::text as computed_tsv
                        FROM document_chunks
                        LIMIT 3
                    """)
                    debug_result = await self.session.execute(debug_stmt)
                debug_rows = debug_result.all()
                logger.info("independent_hybrid_search: DEBUG - Sample chunks content and tsv:")
                for row in debug_rows:
                    logger.info(
                        "  Chunk ID=%d | content_preview='%s' | content_tsv='%s' | computed_tsv='%s'",
                        row[0],
                        row[1][:100] if row[1] else None,
                        row[2] if row[2] else None,
                        row[3] if row[3] else None,
                    )
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∫–∏–µ —Å–ª–æ–≤–∞ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–∞–π–¥–µ–Ω—ã
                query_words = query_text.lower().split()
                logger.info("independent_hybrid_search: DEBUG - Query words: %s", query_words)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞ –æ—Ç–¥–µ–ª—å–Ω–æ
                for word in query_words:
                    word_clean = word.strip('.,!?;:()[]{}"\'')
                    if not word_clean:
                        continue
                    word_query = func.plainto_tsquery("simple", func.unaccent(word_clean))
                    word_count_stmt = select(func.count(DocumentChunk.id)).where(
                        DocumentChunk.content_tsv.op("@@")(word_query)
                    )
                    if document_ids:
                        word_count_stmt = word_count_stmt.where(DocumentChunk.document_id.in_(document_ids))
                    word_count_result = await self.session.execute(word_count_stmt)
                    word_count = word_count_result.scalar() or 0
                    logger.info("independent_hybrid_search: DEBUG - Word '%s' found in %d chunks", word_clean, word_count)
            except Exception as debug_error:
                logger.debug("independent_hybrid_search: debug query failed: %s", str(debug_error))

            # FTS candidates
            fts_sel: Select = select(
                DocumentChunk.id.label("chunk_id"),
                text_rank.label("text_rank"),
                literal(0.0).label("vec_score"),
            ).where(DocumentChunk.content_tsv.op("@@")(ts_query))

            # Vector candidates
            vec_sel: Select = select(
                DocumentChunk.id.label("chunk_id"),
                literal(0.0).label("text_rank"),
                vec_score.label("vec_score"),
            )

            fts_sel = self._apply_filters(
                fts_sel,
                document_ids=document_ids,
                exclude_document_ids=exclude_document_ids,
                include_chunk_ids=include_chunk_ids,
                exclude_chunk_ids=exclude_chunk_ids,
            ).order_by(text_rank.desc()).limit(k_text)

            vec_sel = self._apply_filters(
                vec_sel,
                document_ids=document_ids,
                exclude_document_ids=exclude_document_ids,
                include_chunk_ids=include_chunk_ids,
                exclude_chunk_ids=exclude_chunk_ids,
            ).order_by(vec_score.desc()).limit(k_vector)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ FTS –∏ Vector –æ—Ç–¥–µ–ª—å–Ω–æ
            fts_count_sel = select(func.count()).select_from(fts_sel.subquery())
            vec_count_sel = select(func.count()).select_from(vec_sel.subquery())
            fts_sel_count_result = await self.session.execute(fts_count_sel)
            vec_sel_count_result = await self.session.execute(vec_count_sel)
            fts_sel_count = fts_sel_count_result.scalar() or 0
            vec_sel_count = vec_sel_count_result.scalar() or 0
            logger.info(
                "independent_hybrid_search: FTS candidates=%d | Vector candidates=%d",
                fts_sel_count,
                vec_sel_count,
            )

            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            union_cte = union_all(fts_sel, vec_sel).cte("u")

            # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –ø–æ chunk_id (–±–µ—Ä–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è)
            agg = select(
                union_cte.c.chunk_id.label("chunk_id"),
                func.max(union_cte.c.text_rank).label("text_rank"),
                func.max(union_cte.c.vec_score).label("vec_score"),
            ).group_by(union_cte.c.chunk_id).subquery("agg")

            # –í—ã—á–∏—Å–ª—è–µ–º –≥–∏–±—Ä–∏–¥–Ω—ã–π —Å–∫–æ—Ä
            hybrid = (literal(text_weight) * agg.c.text_rank) + (literal(vector_weight) * agg.c.vec_score)

            stmt: Select = (
                select(
                    DocumentChunk,
                    agg.c.text_rank,
                    agg.c.vec_score,
                    hybrid.label("hybrid_score"),
                )
                .join(agg, agg.c.chunk_id == DocumentChunk.id)
                .order_by(hybrid.desc())
                .limit(limit)
            )

            res = await self.session.execute(stmt)
            rows = res.all()
            hits = [
                SearchHit(
                    chunk=row[0],
                    text_rank=float(row[1] or 0),
                    vec_score=float(row[2] or 0),
                    hybrid_score=float(row[3] or 0),
                )
                for row in rows
            ]
            
            # –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º
            fts_hits_count = sum(1 for h in hits if h.text_rank > 0)
            vec_hits_count = sum(1 for h in hits if h.vec_score > 0)
            logger.info(
                "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n"
                "‚ïë SEARCH COMPLETED                                              ‚ïë\n"
                "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n"
                "‚ïë Total hits: %-51d ‚ïë\n"
                "‚ïë FTS hits: %-53d ‚ïë\n"
                "‚ïë Vector hits: %-50d ‚ïë\n"
                "‚ïë Both methods: %-47d ‚ïë\n"
                "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù",
                len(hits),
                fts_hits_count,
                vec_hits_count,
                sum(1 for h in hits if h.text_rank > 0 and h.vec_score > 0),
            )
            
            # –ï—Å–ª–∏ FTS –Ω–µ –Ω–∞—à–µ–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, –ª–æ–≥–∏—Ä—É–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ
            if fts_hits_count == 0 and fts_count > 0:
                logger.warning(
                    "independent_hybrid_search: FTS found %d matches but text_rank is 0 in results. "
                    "This may indicate an issue with ts_rank_cd calculation.",
                    fts_count
                )
            elif fts_count == 0:
                logger.warning(
                    "independent_hybrid_search: FTS found 0 matches for query '%s'. "
                    "Check if content_tsv is properly indexed or query needs adjustment.",
                    query_text
                )
            
            # –ï—Å–ª–∏ –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, –ø—Ä–æ–±—É–µ–º fallback
            if len(hits) == 0:
                logger.info("independent_hybrid_search: hybrid search returned 0 results, trying fallback")
                # –ü—Ä–æ–±—É–µ–º –æ—Ç–¥–µ–ª—å–Ω–æ FTS –∏ Vector
                fts_hits = await self.fts_search(
                    query_text=query_text,
                    limit=limit,
                    document_ids=document_ids,
                    exclude_document_ids=exclude_document_ids,
                    include_chunk_ids=include_chunk_ids,
                    exclude_chunk_ids=exclude_chunk_ids,
                )
                vec_hits = await self.vector_search(
                    query_embedding=query_embedding,
                    limit=limit,
                    document_ids=document_ids,
                    exclude_document_ids=exclude_document_ids,
                    include_chunk_ids=include_chunk_ids,
                    exclude_chunk_ids=exclude_chunk_ids,
                )
                
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∏ –ø–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä—É–µ–º –≤ –ø–∞–º—è—Ç–∏
                chunk_map = {}
                for hit in fts_hits + vec_hits:
                    chunk_id = hit.chunk.id
                    if chunk_id not in chunk_map:
                        chunk_map[chunk_id] = hit
                    else:
                        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å–∫–æ—Ä—ã
                        existing = chunk_map[chunk_id]
                        chunk_map[chunk_id] = SearchHit(
                            chunk=hit.chunk,
                            text_rank=max(existing.text_rank, hit.text_rank),
                            vec_score=max(existing.vec_score, hit.vec_score),
                            hybrid_score=(text_weight * max(existing.text_rank, hit.text_rank) + 
                                        vector_weight * max(existing.vec_score, hit.vec_score)),
                        )
                
                hits = sorted(chunk_map.values(), key=lambda h: h.hybrid_score, reverse=True)[:limit]
                logger.info("independent_hybrid_search: fallback found %d hits", len(hits))
            
            return hits
        except Exception as e:
            logger.error("independent_hybrid_search: error executing hybrid search: %s", str(e), exc_info=True)
            # Fallback –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –ø–æ–∏—Å–∫–∏
            logger.info("independent_hybrid_search: trying fallback to separate searches")
            try:
                if has_text:
                    fts_hits = await self.fts_search(
                        query_text=query_text,
                        limit=limit,
                        document_ids=document_ids,
                        exclude_document_ids=exclude_document_ids,
                        include_chunk_ids=include_chunk_ids,
                        exclude_chunk_ids=exclude_chunk_ids,
                    )
                    if fts_hits:
                        return fts_hits
                
                if has_vector:
                    vec_hits = await self.vector_search(
                        query_embedding=query_embedding,
                        limit=limit,
                        document_ids=document_ids,
                        exclude_document_ids=exclude_document_ids,
                        include_chunk_ids=include_chunk_ids,
                        exclude_chunk_ids=exclude_chunk_ids,
                    )
                    if vec_hits:
                        return vec_hits
            except Exception as fallback_error:
                logger.error("independent_hybrid_search: fallback also failed: %s", str(fallback_error))
            
            return []
